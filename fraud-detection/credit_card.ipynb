{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(203)\n",
    "\n",
    "data = pd.read_csv(\"./creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Time\"] = data[\"Time\"].apply(lambda x : x / 3600 % 24) # 비율을 나타내고 싶었던 것 같음\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 : 총 31개의 변수\n",
    "\n",
    "Time : 첫번째 transaction으로부터 경과된 시간(초)\n",
    "V1 ~ V28 : PCA 변환된 변수(28개)\n",
    "Amount : 거래 금액\n",
    "Class : Target 변수(0: 정상, 1: 비정상)\n",
    "\n",
    "총 284,807건의 거래내역, 이 중 사기 거래(Fraud Transaction)는 492건"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "LABELS = [\"Non-Fraud\", \"Fraud\"]\n",
    "sns.countplot('Class', data=data, palette=colors)\n",
    "plt.title('Class Distribution \\n (0 : Non-Fraud / 1 : Fraud)', fontsize=13)\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = data['Class'].value_counts().to_frame().reset_index()\n",
    "vc['percent'] = vc[\"Class\"].apply(lambda x : round(100*float(x) / len(data), 2))\n",
    "vc = vc.rename(columns = {\"index\" : \"Target\", \"Class\" : \"Count\"})\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-fraud 거래내역의 1,000행만 사용\n",
    "\n",
    "non_fraud = data[data['Class'] == 0].sample(1000)\n",
    "fraud = data[data['Class'] == 1]\n",
    "\n",
    "df = non_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\n",
    "X = df.drop(['Class'], axis = 1).values\n",
    "Y = df[\"Class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Fraud and Non-Fraud Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치에 대한 기존 데이터의 패턴 파악을 위해 클러스터링을 활용한 거래의 특성 시각화.\n",
    "패턴 존재 여부 파악을 위한 t-SNE 활용으로 거래의 특성 시각화\n",
    "-> 2차원으로 차원 축소하여, 고차원 데이터의 시각화에 사용. \n",
    "-> 각 데이터 포인트 주변으로 유사도를 계산하여, 2차원에서 원본 특성 공간에서 데이터 클러스터링 진행 (이웃 데이터 포인트에 대한 정보 보존 최적화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방식, PCA (linear한 방법으로 클러스터링) : 공분산 행렬에서 고유벡터를 계산하여 진행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', alpha=0.8, label='Fraud')\n",
    "\n",
    "    plt.legend(loc='best');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(X, Y, \"original.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론 : 두 거래의 뚜렷한 특징을 찾기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-encoder를 활용하여, 입력 데이터와 복원덴 데이터 사이의 차이를 계산하여 이상치 탐지 \n",
    "- 가정1 : 데이터가 잘 복원될 경우, 데이터 특성 공간이 잘 파악되었다는 것이며, 데이터 특성 공간이 잘 파악되었다는 것은, 정상 관측치일 가능성이 높다.\n",
    "(즉, 입력된 데이터 특성을 요약하고 복원하는 과정을 포함한 auto-encoder로 자기지도학습을 진행하여, 재구축 오차가 적은 경우를 정상 관측지 / 오차가 큰 경우 이상치 (사기 데이터셋) 로 생각)\n",
    "- 가정에 대한 근거 : 사기 데이터셋이 압도적으로 적은 경우이므로, 비사기 데이터셋을 대상으로 복원 프로세스를 대부분 진행하므로 사기 데이터셋의 재구성은 학습이 거의 안되어 복원이 잘 되지 않을 것\n",
    "\n",
    "(모든 베이스 가정 : 사기 데이터셋과 비사기 데이터셋 간 차이가 존재할 것이다 => 정규분포에서 이것이 잘 드러나면 좋겠으나 적은 데이터셋으로 인해 잘 구분되지 않는 경향성을 보완하고자 auto-encoder 방식 활용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer \n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
    "\n",
    "# autoencoder \n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 변수의 범위가 다른 것을 스케일링하여 전처리 : 2,000행의 비사기 케이스만 활용하여 학습 (적은 데이터셋으로도 구분 가능)\n",
    "\n",
    "x = data.drop([\"Class\"], axis=1)\n",
    "y = data[\"Class\"].values\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_norm[0:2000], x_norm[0:2000], batch_size = 256, epochs = 10, shuffle = True, validation_split = 0.20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_hid_rep = hidden_representation.predict(x_norm[:3000])\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud)\n",
    "\n",
    "# 입력에 대한 잠재 변수 표현. sequential layer 포함하는 네트워크를 생성해 input에 대한 예측을 통해 잠재 변수를 추출.\n",
    "# 즉, fraud와 non-fraud에 대한 두 숨겨진 표현 (잠재 표현)을 생성함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "tsne_plot(rep_x, rep_y, \"latent_representation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화 한 결과, 잠재변수를 활용할 경우 훨씬 classifier에 적합한 형태를 만들 수 있음을 보임.\n",
    "이렇게 할 경우 간단한 linear classifier 만으로도 변별이 가능함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear classifier : using Ligistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print('Logistic Regression Accuracy Score: ', round(accuracy_score(val_y, pred_y) * 100, 3).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_pred=pred_y, y_true=val_y)\n",
    "cmp = ConfusionMatrixDisplay(cm)\n",
    "cmp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 873건 (744 + 129) \n",
    "성능 : 129건의 fraud중 114건은 맞추고, 17건은 틀림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what can i do..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 식으로, 뭔가 특징이 불분명해서 내가 임의로 조작해야만 결과가 잘 나올 수 있는 사기/비사기 데이터셋에 대해,\n",
    "문득 드는 생각 : 모델의 robust를 측정하기 위한 작업이 유의미한 작업인가?\n",
    "\n",
    "- 원래 하려던 것\n",
    "1. 사기 데이터셋에서 값 변형을 일부만 주어 비사기 데이터셋으로 분류하는지 확인하기 \n",
    "2. 데이터셋이 없다는 가정 하에서, 그냥 랜덤한 값들을 쭉 던지며 이상치/비이상치 값을 구분하는 선형 분류 함수의 라인 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가작업 : 지도학습 말고 다른 학습 방식 없는 지 찾아보기!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
